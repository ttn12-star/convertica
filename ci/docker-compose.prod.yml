# Production Docker Compose configuration
# Usage: docker compose -f docker-compose.yml -f ci/docker-compose.prod.yml up -d

services:
  nginx:
    # Use nginx with Brotli support
    build:
      context: .
      dockerfile: ci/nginx.Dockerfile
    # Note: profiles removed - nginx should always be available in production
    # IMPORTANT: Using service_started instead of service_healthy to avoid deadlock
    # when web crashes - nginx should start independently and show 502 if web is down
    depends_on:
      web:
        condition: service_started
    healthcheck:
      # Check nginx is responding (health endpoint is served directly by nginx)
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "--header=Host: convertica.net", "http://127.0.0.1/health/"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: always
    labels:
      - "autoheal=true"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  web:
    build:
      context: .
      dockerfile: ci/Dockerfile
    command: >
      sh -c "python /app/clear_staticfiles.py || true &&
             python manage.py collectstatic --noinput &&
             /app/scripts/compress_static.sh /app/staticfiles || true &&
             python /app/ci/generate_robots_txt.py || true &&
             python /app/create_manifest.py || true &&
             python manage.py makemessages -l en -l ru -l es -l pl -l hi -l id -l ar --no-location --no-obsolete || true &&
             python manage.py compilemessages &&
             python manage.py migrate --noinput &&
             gunicorn --config /app/ci/gunicorn.conf.py utils_site.wsgi:application"
    env_file:
      - .env
    environment:
      - SENTRY_ENVIRONMENT=${SENTRY_ENVIRONMENT:-production}
      - SENTRY_RELEASE=${SENTRY_RELEASE}
      - SITE_DOMAIN=${SITE_DOMAIN:-convertica.net}
    deploy:
      resources:
        limits:
          cpus: '${WEB_CPU_LIMIT:-1.0}'
          memory: ${WEB_MEMORY_LIMIT:-1.8G}
        reservations:
          cpus: '${WEB_CPU_RESERVATION:-0.5}'
          memory: ${WEB_MEMORY_RESERVATION:-1G}
    # Allow container to use host swap (memory + swap total = 2.5G)
    # Without this, container is killed when hitting memory limit even if host has swap
    memswap_limit: 2.5G
    healthcheck:
      # Use /livez/ for liveness check (doesn't depend on DB/Redis)
      # This prevents false unhealthy status when DB/Redis are slow
      test: ["CMD", "curl", "-f", "http://localhost:8000/livez/"]
      interval: 15s
      timeout: 10s
      retries: 3
      start_period: 120s
    restart: always
    # Give gunicorn 30s to gracefully shutdown (default is 10s which is too short)
    stop_grace_period: 30s
    labels:
      - "autoheal=true"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  celery:
    build:
      context: .
      dockerfile: ci/Dockerfile
    command: celery -A utils_site worker --loglevel=info --concurrency=${CELERY_CONCURRENCY:-2} --pool=prefork --max-tasks-per-child=500 -Q celery,default,maintenance,regular
    env_file:
      - .env
    environment:
      - SENTRY_ENVIRONMENT=${SENTRY_ENVIRONMENT:-production}
      - SENTRY_RELEASE=${SENTRY_RELEASE}
      - SITE_DOMAIN=${SITE_DOMAIN:-convertica.net}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '${CELERY_CPU_LIMIT:-0.5}'
          # Increased from 512M to 1G for heavy PDF operations (image-heavy files)
          # PDF to Word/Excel can use 500-800MB for large files
          memory: ${CELERY_MEMORY_LIMIT:-1G}
        reservations:
          cpus: '${CELERY_CPU_RESERVATION:-0.2}'
          memory: ${CELERY_MEMORY_RESERVATION:-256M}
    # Allow celery to use swap for heavy PDF operations (memory + swap = 1.5G)
    memswap_limit: 1.5G
    healthcheck:
      test: ["CMD-SHELL", "celery -A utils_site inspect ping -d celery@$$HOSTNAME || exit 0"]
      interval: 60s
      timeout: 30s
      retries: 10
      start_period: 30s
    restart: always
    labels:
      - "autoheal=true"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  celery-beat:
    build:
      context: .
      dockerfile: ci/Dockerfile
    command: celery -A utils_site beat --loglevel=info --schedule=/app/celerybeat-schedule/celerybeat-schedule.db
    volumes:
      - celery-beat-schedule:/app/celerybeat-schedule
    env_file:
      - .env
    environment:
      - SENTRY_ENVIRONMENT=${SENTRY_ENVIRONMENT:-production}
      - SENTRY_RELEASE=${SENTRY_RELEASE}
      - SITE_DOMAIN=${SITE_DOMAIN:-convertica.net}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '${CELERY_BEAT_CPU_LIMIT:-0.1}'
          memory: ${CELERY_BEAT_MEMORY_LIMIT:-256M}  # Increased from 128M - Django import needs memory at startup
        reservations:
          cpus: '${CELERY_BEAT_CPU_RESERVATION:-0.05}'
          memory: ${CELERY_BEAT_MEMORY_RESERVATION:-128M}
    healthcheck:
      test: ["CMD", "sh", "-c", "pgrep -f 'celery.*beat' > /dev/null && test -f /app/celerybeat-schedule/celerybeat-schedule.db || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    labels:
      - "autoheal=true"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  db:
    deploy:
      resources:
        limits:
          cpus: '${DB_CPU_LIMIT:-0.3}'
          memory: ${DB_MEMORY_LIMIT:-256M}
        reservations:
          cpus: '${DB_CPU_RESERVATION:-0.1}'
          memory: ${DB_MEMORY_RESERVATION:-128M}
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis:
    deploy:
      resources:
        limits:
          cpus: '${REDIS_CPU_LIMIT:-0.25}'
          memory: ${REDIS_MEMORY_LIMIT:-384M}
        reservations:
          cpus: '${REDIS_CPU_RESERVATION:-0.05}'
          memory: ${REDIS_MEMORY_RESERVATION:-128M}
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Autoheal - automatically restarts unhealthy containers
  autoheal:
    image: willfarrell/autoheal:latest
    restart: always
    environment:
      - AUTOHEAL_CONTAINER_LABEL=autoheal
      - AUTOHEAL_INTERVAL=30
      - AUTOHEAL_START_PERIOD=120
      - AUTOHEAL_DEFAULT_STOP_TIMEOUT=10
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 64M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # Docker monitor - sends Telegram alerts when containers die/restart
  docker-monitor:
    image: docker:cli
    restart: always
    entrypoint: /bin/sh
    command: ["/monitor.sh"]
    environment:
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./ci/docker-monitor.sh:/monitor.sh:ro
    deploy:
      resources:
        limits:
          cpus: '0.05'
          memory: 32M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

volumes:
  celery-beat-schedule:
    driver: local
