# Production Docker Compose configuration
# Usage: docker compose -f docker-compose.yml -f ci/docker-compose.prod.yml up -d

services:
  nginx:
    # Healthcheck removed - container status sufficient
    profiles:
      - production

  web:
    build:
      context: .
      dockerfile: ci/Dockerfile
    command: >
      sh -c "python /app/clear_staticfiles.py || true &&
             python manage.py collectstatic --noinput &&
             python /app/ci/generate_robots_txt.py || true &&
             python /app/create_manifest.py || true &&
             python manage.py makemessages -l en -l ru -l es -l pl -l hi -l id -l ar --no-location --no-obsolete || true &&
             python manage.py compilemessages &&
             python manage.py migrate users 0001_initial --fake-initial &&
             python manage.py migrate users 0002_alter_user_user_manager &&
             python manage.py migrate users 0003_migrate_existing_users &&
             python manage.py migrate &&
             gunicorn --bind 0.0.0.0:8000 --workers ${GUNICORN_WORKERS:-1} --threads ${GUNICORN_THREADS:-2} --timeout 300 --graceful-timeout 30 --max-requests 500 --max-requests-jitter 50 --access-logfile - --error-logfile - --log-level info --worker-class gthread --preload utils_site.wsgi:application"
    env_file:
      - .env
    environment:
      - SENTRY_ENVIRONMENT=${SENTRY_ENVIRONMENT:-production}
      - SENTRY_RELEASE=${SENTRY_RELEASE}
      - SITE_DOMAIN=${SITE_DOMAIN:-convertica.net}
    deploy:
      resources:
        limits:
          cpus: '${WEB_CPU_LIMIT:-0.8}'
          memory: ${WEB_MEMORY_LIMIT:-1.5G}
        reservations:
          cpus: '${WEB_CPU_RESERVATION:-0.4}'
          memory: ${WEB_MEMORY_RESERVATION:-1G}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health/"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 90s
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  celery:
    build:
      context: .
      dockerfile: ci/Dockerfile
    command: celery -A utils_site worker --loglevel=info --concurrency=${CELERY_CONCURRENCY:-1} --max-tasks-per-child=500 -Q celery,default,maintenance
    env_file:
      - .env
    environment:
      - SENTRY_ENVIRONMENT=${SENTRY_ENVIRONMENT:-production}
      - SENTRY_RELEASE=${SENTRY_RELEASE}
      - SITE_DOMAIN=${SITE_DOMAIN:-convertica.net}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '${CELERY_CPU_LIMIT:-0.5}'
          # Increased from 512M to 1G for heavy PDF operations (image-heavy files)
          # PDF to Word/Excel can use 500-800MB for large files
          memory: ${CELERY_MEMORY_LIMIT:-1G}
        reservations:
          cpus: '${CELERY_CPU_RESERVATION:-0.2}'
          memory: ${CELERY_MEMORY_RESERVATION:-256M}
    healthcheck:
      test: ["CMD", "sh", "-c", "celery -A utils_site inspect ping -d celery@$$HOSTNAME > /dev/null 2>&1 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  celery-beat:
    build:
      context: .
      dockerfile: ci/Dockerfile
    command: celery -A utils_site beat --loglevel=info --schedule=/app/celerybeat-schedule/celerybeat-schedule.db
    volumes:
      - celery-beat-schedule:/app/celerybeat-schedule
    env_file:
      - .env
    environment:
      - SENTRY_ENVIRONMENT=${SENTRY_ENVIRONMENT:-production}
      - SENTRY_RELEASE=${SENTRY_RELEASE}
      - SITE_DOMAIN=${SITE_DOMAIN:-convertica.net}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '${CELERY_BEAT_CPU_LIMIT:-0.1}'
          memory: ${CELERY_BEAT_MEMORY_LIMIT:-128M}
        reservations:
          cpus: '${CELERY_BEAT_CPU_RESERVATION:-0.05}'
          memory: ${CELERY_BEAT_MEMORY_RESERVATION:-64M}
    healthcheck:
      test: ["CMD", "sh", "-c", "pgrep -f 'celery.*beat' > /dev/null && test -f /app/celerybeat-schedule/celerybeat-schedule.db || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  db:
    deploy:
      resources:
        limits:
          cpus: '${DB_CPU_LIMIT:-0.3}'
          memory: ${DB_MEMORY_LIMIT:-256M}
        reservations:
          cpus: '${DB_CPU_RESERVATION:-0.1}'
          memory: ${DB_MEMORY_RESERVATION:-128M}
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis:
    deploy:
      resources:
        limits:
          cpus: '${REDIS_CPU_LIMIT:-0.25}'
          memory: ${REDIS_MEMORY_LIMIT:-384M}
        reservations:
          cpus: '${REDIS_CPU_RESERVATION:-0.05}'
          memory: ${REDIS_MEMORY_RESERVATION:-128M}
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  celery-beat-schedule:
    driver: local
